---
layout: default
title: hive的sort by和distribute by 
---

 {{ page.title }}
================
<p class="meta">6 May 2012 - GuangZhou</p>

之前认为我们的部分数据需求，hive是解决不了的，只能用hadoop编码实现。前两周跟小马解决玩家升级时间需求，本来我想用hadoop编码，但小马都是用hive编码的，为了保持大家编码的一致性，于是再次学习hive语法，完成了这个需求。事后想了想，针对我们数据特点，我们所有的数据处理，其实都是可以用hive完成。  
先说明一下玩家升级时间需求，策划想了解新手玩家每个等级的在线时间和升级时间。而后台数据有  
*  玩家每次登录、退出记录:有玩家角色ID、登录时间戳、退出时间戳、总在线时长字段、登录等级、退出等级等字段;  
*  玩家升级记录:有玩家角色ID、升级时间戳等字段。

以前在单机下处理这个数据需求的时候，比较简单。  
*  先抽取玩家的登录退出、升级记录，然后混合所有记录，标记每行记录的玩家行为（登录、升级、退出）；  
*  然后利用玩家角色ID、时间戳进行混合数据排序;  
*  因为数据以及排序，所以可以放心迭代解析每行记录，利用时间戳相加减，计算出每个玩家每个等级的在线时长。  

在hive下处理这个需求其实过程思路一样。  
*  混合数据记录。通过hive自定义脚本MAP (fields) USING (fields) AS (mapfields)，再结合union，就可以混合不同数据表的记录了；  
*  排序过程，利用hive的SORT BY和DISTRIBUTE BY。因为升级时间计算是否正确，相同玩家角色ID的记录必须在同一个reduce端。之前一直认为SORT BY和DISTRIBUTE BY作用微乎其微，但通过这个升级数据需求，悟到SORT BY和DISTRIBUTE BY控制hadoop 数据从map端转向reduce端的排序、分拆过程，对我们一些特定数据需求是非常方便的。再深层次，我们部分数据需求的hadoop代码其实可以用hive实现。  
*  迭代解析记录。也是利用hive自定义脚本实现。

本以为自己了解大部分hive语法，但一些语法的深层次应用和过程机制，我还只是略知皮毛。
